{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_dsb_kids_game.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa93fae2e1d745e497da85491e79b4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72385b43c8db406db1bb378fb2f6ada3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d27fcb085a8044faa4b3044b025c3e34",
              "IPY_MODEL_de569291be0b4e0ba35494cc05b80c24"
            ]
          }
        },
        "72385b43c8db406db1bb378fb2f6ada3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d27fcb085a8044faa4b3044b025c3e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b891a50eb7664b2788a5f9a2b94d0c71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_499a75c2e8754b6895fa07f3498ed03c"
          }
        },
        "de569291be0b4e0ba35494cc05b80c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ba46900de9740d78cec8ad13bd4bfe5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "119it [01:11,  1.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbef143908964ac192c569265babaac3"
          }
        },
        "b891a50eb7664b2788a5f9a2b94d0c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "499a75c2e8754b6895fa07f3498ed03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ba46900de9740d78cec8ad13bd4bfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbef143908964ac192c569265babaac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc83cc8e8a2c45369e5b28ae4f382ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c79fdb6b7fc40fbb8da1003c2a6e2ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d8308ff28eb4cc08d3d998b9a1764f8",
              "IPY_MODEL_7098dad9609f476c947a34aebfc36c95"
            ]
          }
        },
        "2c79fdb6b7fc40fbb8da1003c2a6e2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d8308ff28eb4cc08d3d998b9a1764f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81aeb10b381d4f22abadd21344385b4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85c9f8c2d72d425dbbc7b04ac9ea0806"
          }
        },
        "7098dad9609f476c947a34aebfc36c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_503ca5cd969b41d9aee2efb78f148661",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "51it [00:30,  1.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_729ae60ef6df488e9676e3760984ff77"
          }
        },
        "81aeb10b381d4f22abadd21344385b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85c9f8c2d72d425dbbc7b04ac9ea0806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "503ca5cd969b41d9aee2efb78f148661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "729ae60ef6df488e9676e3760984ff77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshavkmr48/Kaggle/blob/master/NLP_DISASTER_TWEET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OEZ_beau2Bn",
        "colab_type": "text"
      },
      "source": [
        "# **Setting up kaggle API to download competition dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spsRa-6uyD5",
        "colab_type": "code",
        "outputId": "e4937f49-bca7-4609-b517-a7d773bae6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# !pip install kaggle --upgrade\n",
        "!pip install transformers\n",
        "\n",
        "! mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"keshavkmr48\",\"key\":\"014d22aa9430a95daaf028ec3e3463a2\"}\n",
        "with open('/content/.kaggle/kaggle.json','w') as file:\n",
        "  json.dump(token,file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# download competition data\n",
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.40)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers) (2.6.1)\n",
            "- path is now set to: {/content}\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 40.8MB/s]\n",
            "Downloading test.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 55.8MB/s]\n",
            "Downloading train.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 63.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aobPTFygwpdG",
        "colab_type": "text"
      },
      "source": [
        "# **Loading Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU618r3FwshF",
        "colab_type": "code",
        "outputId": "6fa28c0c-98bf-4d38-b627-1d5f406c0abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from xgboost import plot_importance\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import ensemble\n",
        "# from catboost import CatBoostRegressor\n",
        "from matplotlib import pyplot\n",
        "# import shap\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import gc, os\n",
        "import json\n",
        "import string,re\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "from wordcloud import STOPWORDS\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import joblib\n",
        "pd.set_option('display.max_columns', 1000)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BwhOVDDxF7p",
        "colab_type": "text"
      },
      "source": [
        "# ***Reading all tain,test and submission data file***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2HHLEk32NP",
        "colab_type": "code",
        "outputId": "f54050a4-ef6f-4a77-de78-0adf5ea8cacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# list data in the downloaded folder\n",
        "#os.listdir('{/content}/competitions/data-science-bowl-2019')\n",
        "os.chdir('{/content}/competitions/nlp-getting-started')\n",
        "os.listdir()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.csv', 'train.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp1SSLMvw9yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    print('Reading train.csv file....')\n",
        "    train = pd.read_csv('train.csv')\n",
        "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
        "\n",
        "    print('Reading test.csv file....')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
        "\n",
        "\n",
        "    print('Reading sample_submission.csv file....')\n",
        "    sample_submission = pd.read_csv('sample_submission.csv')\n",
        "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
        "    return train, test, sample_submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYp1vR9y0fw",
        "colab_type": "code",
        "outputId": "c2fdb74a-e6ab-47f1-aa69-fc49915d76e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train, test, sample_submission = read_data()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train.csv file....\n",
            "Training.csv file have 7613 rows and 5 columns\n",
            "Reading test.csv file....\n",
            "Test.csv file have 3263 rows and 4 columns\n",
            "Reading sample_submission.csv file....\n",
            "Sample_submission.csv file have 3263 rows and 2 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MvQIXL8wZ1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from multiprocessing import Pool\n",
        "\n",
        "# def json_loader(x):\n",
        "#   return json.loads(x)\n",
        "# pool = Pool(4)\n",
        "# result = pool.map_async(json_loader,train.event_data)\n",
        "# df = pd.DataFrame(list(result.get()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWJUXQCKx8Kg",
        "colab_type": "text"
      },
      "source": [
        "# ***Peak into data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8wZoEmDy51E",
        "colab_type": "code",
        "outputId": "0778eb78-1bd5-4b93-b055-571d2133eef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSZlL8c2pRgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.text = train.text.astype('str')\n",
        "test.text = test.text.astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_HEy4b0xg6J",
        "colab_type": "text"
      },
      "source": [
        "# ***Slang , Misspelling and Stopword dictionary***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsHvjkdhMKM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slang_abbrev_dict = {\n",
        "    'AFAIK': 'As Far As I Know','AFK': 'Away From Keyboard','ASAP': 'As Soon As Possible','ATK': 'At The Keyboard','ATM': 'At The Moment','A3': 'Anytime, Anywhere, Anyplace',\n",
        "    'BAK': 'Back At Keyboard','BBL': 'Be Back Later','BBS': 'Be Back Soon','BFN': 'Bye For Now','B4N': 'Bye For Now','BRB': 'Be Right Back','BRT': 'Be Right There',\n",
        "    'BTW': 'By The Way','B4': 'Before','B4N': 'Bye For Now','CU': 'See You','CUL8R': 'See You Later','CYA': 'See You','FAQ': 'Frequently Asked Questions',\n",
        "    'FC': 'Fingers Crossed','FWIW': 'For What It\\'s Worth','FYI': 'For Your Information','GAL': 'Get A Life','GG': 'Good Game','GN': 'Good Night','GMTA': 'Great Minds Think Alike',\n",
        "    'GR8': 'Great!','G9': 'Genius','IC': 'I See','ICQ': 'I Seek you','ILU': 'I Love You','IMHO': 'In My Humble Opinion','IMO': 'In My Opinion','IOW': 'In Other Words',\n",
        "    'IRL': 'In Real Life','KISS': 'Keep It Simple, Stupid','LDR': 'Long Distance Relationship','LMAO': 'Laugh My Ass Off','LOL': 'Laughing Out Loud',\n",
        "    'LTNS': 'Long Time No See','L8R': 'Later','MTE': 'My Thoughts Exactly','M8': 'Mate','NRN': 'No Reply Necessary','OIC': 'Oh I See','OMG': 'Oh My God',\n",
        "    'PITA': 'Pain In The Ass','PRT': 'Party','PRW': 'Parents Are Watching','QPSA?': 'Que Pasa?','ROFL': 'Rolling On The Floor Laughing','ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
        "    'ROTFLMAO': 'Rolling On The Floor Laughing My Ass Off','SK8': 'Skate','STATS': 'Your sex and age','ASL': 'Age, Sex, Location','THX': 'Thank You','TTFN': 'Ta-Ta For Now!',\n",
        "    'TTYL': 'Talk To You Later','U': 'You','U2': 'You Too','U4E': 'Yours For Ever','WB': 'Welcome Back','WTF': 'What The Fuck','WTG': 'Way To Go!',\n",
        "    'WUF': 'Where Are You From?','W8': 'Wait','7K': 'Sick:-D Laugher'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "649au26mMKQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mispell_dict = {\"aren't\" : \"are not\",\"can't\" : \"cannot\",\"couldn't\" : \"could not\",\"couldnt\" : \"could not\",\"didn't\" : \"did not\",\"doesn't\" : \"does not\",\n",
        "\"doesnt\" : \"does not\",\"don't\" : \"do not\",\"hadn't\" : \"had not\",\"hasn't\" : \"has not\",\"haven't\" : \"have not\",\"havent\" : \"have not\",\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\"he's\" : \"he is\",\"i'd\" : \"I would\",\"i'd\" : \"I had\",\"i'll\" : \"I will\",\"i'm\" : \"I am\",\"isn't\" : \"is not\",\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\"i've\" : \"I have\",\"let's\" : \"let us\",\"mightn't\" : \"might not\",\"mustn't\" : \"must not\",\"shan't\" : \"shall not\",\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\"she's\" : \"she is\",\"shouldn't\" : \"should not\",\"shouldnt\" : \"should not\",\"that's\" : \"that is\",\"thats\" : \"that is\",\"there's\" : \"there is\",\n",
        "\"theres\" : \"there is\",\"they'd\" : \"they would\",\"they'll\" : \"they will\",\"they're\" : \"they are\",\"theyre\":  \"they are\",\"they've\" : \"they have\",\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\"weren't\" : \"were not\",\"we've\" : \"we have\",\"what'll\" : \"what will\",\"what're\" : \"what are\",\"what's\" : \"what is\",\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\"who'd\" : \"who would\",\"who'll\" : \"who will\",\"who're\" : \"who are\",\"who's\" : \"who is\",\"who've\" : \"who have\",\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\"you'd\" : \"you would\",\"you'll\" : \"you will\",\"you're\" : \"you are\",\"you've\" : \"you have\",\"'re\": \" are\",\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\"didn't\": \"did not\",\"tryin'\":\"trying\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfMJ7diXMKWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    add_stopwords=[\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\",\"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\",\n",
        "    \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\",\"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\",\"doesn't\", \n",
        "    \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\",\"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\",\n",
        "    \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\",\n",
        "    \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\",\"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\",\n",
        "    \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\",\"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\n",
        "    \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\",\"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\",\n",
        "    \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\",\"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\",\n",
        "    \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\",\"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\",\n",
        "    \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\",\"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
        "    \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\",\"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\",\n",
        "    \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\",\"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\", \"able\", \"abst\",\n",
        "    \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\",\"added\", \"adj\", \"affected\", \"affecting\", \"affects\", \"afterwards\", \"ah\",\n",
        "    \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\"among\", \"amongst\", \"announce\", \"another\", \"anybody\", \"anyhow\", \"anymore\",\n",
        "    \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\",\"approximately\", \"arent\", \"arise\", \"around\", \"aside\", \"ask\", \"asking\",\n",
        "    \"auth\", \"available\", \"away\", \"awfully\", \"b\", \"back\", \"became\", \"become\",\"becomes\", \"becoming\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\",\n",
        "    \"begins\", \"behind\", \"believe\", \"beside\", \"besides\", \"beyond\", \"biol\",\"brief\", \"briefly\", \"c\", \"ca\", \"came\", \"cannot\", \"can't\", \"cause\", \"causes\",\n",
        "    \"certain\", \"certainly\", \"co\", \"com\", \"come\", \"comes\", \"contain\",\"containing\", \"contains\", \"couldnt\", \"date\", \"different\", \"done\",\n",
        "    \"downwards\", \"due\", \"e\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \"eighty\",\"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \"especially\",\n",
        "    \"et\", \"etc\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\",\"everywhere\", \"ex\", \"except\", \"f\", \"far\", \"ff\", \"fifth\", \"first\", \"five\",\n",
        "    \"fix\", \"followed\", \"following\", \"follows\", \"former\", \"formerly\", \"forth\",\"found\", \"four\", \"furthermore\", \"g\", \"gave\", \"get\", \"gets\", \"getting\",\n",
        "    \"give\", \"given\", \"gives\", \"giving\", \"go\", \"goes\", \"gone\", \"got\", \"gotten\",\"h\", \"happens\", \"hardly\", \"hed\", \"hence\", \"hereafter\", \"hereby\", \"herein\",\n",
        "    \"heres\", \"hereupon\", \"hes\", \"hi\", \"hid\", \"hither\", \"home\", \"howbeit\",\"however\", \"hundred\", \"id\", \"ie\", \"im\", \"immediate\", \"immediately\",\n",
        "    \"importance\", \"important\", \"inc\", \"indeed\", \"index\", \"information\",\"instead\", \"invention\", \"inward\", \"itd\", \"it'll\", \"j\", \"k\", \"keep\", \"keeps\",\n",
        "    \"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\",\"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \"let\",\n",
        "    \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"'ll\", \"look\",\"looking\", \"looks\", \"ltd\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\",\n",
        "    \"maybe\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\",\"million\", \"miss\", \"ml\", \"moreover\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\",\n",
        "    \"must\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \"near\", \"nearly\",\"necessarily\", \"necessary\", \"need\", \"needs\", \"neither\", \"never\",\n",
        "    \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \"nobody\", \"non\", \"none\",\"nonetheless\", \"noone\", \"normally\", \"nos\", \"noted\", \"nothing\", \"nowhere\",\n",
        "    \"obtain\", \"obtained\", \"obviously\", \"often\", \"oh\", \"ok\", \"okay\", \"old\",\"omitted\", \"one\", \"ones\", \"onto\", \"ord\", \"others\", \"otherwise\", \"outside\",\n",
        "    \"overall\", \"owing\", \"p\", \"page\", \"pages\", \"part\", \"particular\",\"particularly\", \"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\",\n",
        "    \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\",\"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\",\n",
        "    \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"ran\",\"rather\", \"rd\", \"readily\", \"really\", \"recent\", \"recently\", \"ref\", \"refs\",\n",
        "    \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\",\"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"run\", \"said\",\n",
        "    \"saw\", \"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\",\"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \"seven\",\n",
        "    \"several\", \"shall\", \"shed\", \"shes\", \"show\", \"showed\", \"shown\", \"showns\",\"shows\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\",\n",
        "    \"six\", \"slightly\", \"somebody\", \"somehow\", \"someone\", \"somethan\",\"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\",\n",
        "    \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"still\",\"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"sufficiently\",\n",
        "    \"suggest\", \"sup\", \"sure\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\",\"thank\", \"thanks\", \"thanx\", \"thats\", \"that've\", \"thence\", \"thereafter\",\n",
        "    \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\",\"therere\", \"theres\", \"thereto\", \"thereupon\", \"there've\", \"theyd\", \"theyre\",\n",
        "    \"think\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"throug\", \"throughout\",\"thru\", \"thus\", \"til\", \"tip\", \"together\", \"took\", \"toward\", \"towards\",\n",
        "    \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\",\"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"unto\", \"upon\", \"ups\",\n",
        "    \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\",\"usually\", \"v\", \"value\", \"various\", \"'ve\", \"via\", \"viz\", \"vol\", \"vols\",\n",
        "    \"vs\", \"w\", \"want\", \"wants\", \"wasnt\", \"way\", \"wed\", \"welcome\", \"went\",\"werent\", \"whatever\", \"what'll\", \"whats\", \"whence\", \"whenever\",\n",
        "    \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\",\"wherever\", \"whether\", \"whim\", \"whither\", \"whod\", \"whoever\", \"whole\",\n",
        "    \"who'll\", \"whomever\", \"whos\", \"whose\", \"widely\", \"willing\", \"wish\",\"within\", \"without\", \"wont\", \"words\", \"world\", \"wouldnt\", \"www\", \"x\", \"yes\",\n",
        "    \"yet\", \"youd\", \"youre\", \"z\", \"zero\", \"a's\", \"ain't\", \"allow\", \"allows\",\"apart\", \"appear\", \"appreciate\", \"appropriate\", \"associated\", \"best\",\n",
        "    \"better\", \"c'mon\", \"c's\", \"cant\", \"changes\", \"clearly\", \"concerning\",\"consequently\", \"consider\", \"considering\", \"corresponding\", \"course\",\n",
        "    \"currently\", \"definitely\", \"described\", \"despite\", \"entirely\", \"exactly\",\"example\", \"going\", \"greetings\", \"hello\", \"help\", \"hopefully\", \"ignored\",\n",
        "    \"inasmuch\", \"indicate\", \"indicated\", \"indicates\", \"inner\", \"insofar\",\"it'd\", \"keep\", \"keeps\", \"novel\", \"presumably\", \"reasonably\", \"second\",\n",
        "    \"secondly\", \"sensible\", \"serious\", \"seriously\", \"sure\", \"t's\", \"third\",\"thorough\", \"thoroughly\", \"three\", \"well\", \"wonder\", \"a\", \"about\", \"above\",\n",
        "    \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\",\"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\",\n",
        "    \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\",\"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\", \"around\", \"as\",\n",
        "    \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\",\"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\",\n",
        "    \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\",\"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\",\n",
        "    \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\",\"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\",\n",
        "    \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\",\"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\",\n",
        "    \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\",\"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\",\n",
        "    \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\",\"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\",\n",
        "    \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\",\"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\",\n",
        "    \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\",\"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\",\n",
        "    \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\",\"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\",\n",
        "    \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\",\"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\n",
        "    \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\",\"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\",\n",
        "    \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\",\"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\",\n",
        "    \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
        "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\",\"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
        "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
        "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
        "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\",\n",
        "    \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\"the\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\n",
        "    \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \"A\", \"B\", \"C\",\"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\",\n",
        "    \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"co\", \"op\", \"research-articl\",\"pagecount\", \"cit\", \"ibid\", \"les\", \"le\", \"au\", \"que\", \"est\", \"pas\", \"vol\",\n",
        "    \"el\", \"los\", \"pp\", \"u201d\", \"well-b\", \"http\", \"volumtype\", \"par\", \"0o\",\"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"ac\",\n",
        "    \"ad\", \"ae\", \"af\", \"ag\", \"aj\", \"al\", \"an\", \"ao\", \"ap\", \"ar\", \"av\", \"aw\",\"ax\", \"ay\", \"az\", \"b1\", \"b2\", \"b3\", \"ba\", \"bc\", \"bd\", \"be\", \"bi\", \"bj\",\n",
        "    \"bk\", \"bl\", \"bn\", \"bp\", \"br\", \"bs\", \"bt\", \"bu\", \"bx\", \"c1\", \"c2\", \"c3\",\"cc\", \"cd\", \"ce\", \"cf\", \"cg\", \"ch\", \"ci\", \"cj\", \"cl\", \"cm\", \"cn\", \"cp\",\n",
        "    \"cq\", \"cr\", \"cs\", \"ct\", \"cu\", \"cv\", \"cx\", \"cy\", \"cz\", \"d2\", \"da\", \"dc\",\"dd\", \"de\", \"df\", \"di\", \"dj\", \"dk\", \"dl\", \"do\", \"dp\", \"dr\", \"ds\", \"dt\",\n",
        "    \"du\", \"dx\", \"dy\", \"e2\", \"e3\", \"ea\", \"ec\", \"ed\", \"ee\", \"ef\", \"ei\", \"ej\",\"el\", \"em\", \"en\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"et\", \"eu\", \"ev\", \"ex\",\n",
        "    \"ey\", \"f2\", \"fa\", \"fc\", \"ff\", \"fi\", \"fj\", \"fl\", \"fn\", \"fo\", \"fr\", \"fs\", \"ft\", \"fu\", \"fy\", \"ga\", \"ge\", \"gi\", \"gj\", \"gl\", \"go\", \"gr\", \"gs\", \"gy\",\n",
        "    \"h2\", \"h3\", \"hh\", \"hi\", \"hj\", \"ho\", \"hr\", \"hs\", \"hu\", \"hy\", \"i\", \"i2\", \"i3\",\"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ic\", \"ie\", \"ig\", \"ih\", \"ii\", \"ij\",\"il\", \"in\", \"io\", \"ip\", \"iq\", \"ir\", \"iv\", \"ix\", \"iy\", \"iz\", \"jj\", \"jr\",\n",
        "    \"js\", \"jt\", \"ju\", \"ke\", \"kg\", \"kj\", \"km\", \"ko\", \"l2\", \"la\", \"lb\", \"lc\",\"lf\", \"lj\", \"ln\", \"lo\", \"lr\", \"ls\", \"lt\", \"m2\", \"ml\", \"mn\", \"mo\", \"ms\",\n",
        "    \"mt\", \"mu\", \"n2\", \"nc\", \"nd\", \"ne\", \"ng\", \"ni\", \"nj\", \"nl\", \"nn\", \"nr\",\"ns\", \"nt\", \"ny\", \"oa\", \"ob\", \"oc\", \"od\", \"of\", \"og\", \"oi\", \"oj\", \"ol\",\n",
        "    \"om\", \"on\", \"oo\", \"oq\", \"or\", \"os\", \"ot\", \"ou\", \"ow\", \"ox\", \"oz\", \"p1\",\"p2\", \"p3\", \"pc\", \"pd\", \"pe\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"pm\",\n",
        "    \"pn\", \"po\", \"pq\", \"pr\", \"ps\", \"pt\", \"pu\", \"py\", \"qj\", \"qu\", \"r2\", \"ra\",\"rc\", \"rd\", \"rf\", \"rh\", \"ri\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\",\n",
        "    \"rs\", \"rt\", \"ru\", \"rv\", \"ry\", \"s2\", \"sa\", \"sc\", \"sd\", \"se\", \"sf\", \"si\",\"sj\", \"sl\", \"sm\", \"sn\", \"sp\", \"sq\", \"sr\", \"ss\", \"st\", \"sy\", \"sz\", \"t1\",\n",
        "    \"t2\", \"t3\", \"tb\", \"tc\", \"td\", \"te\", \"tf\", \"th\", \"ti\", \"tj\", \"tl\", \"tm\",\"tn\", \"tp\", \"tq\", \"tr\", \"ts\", \"tt\", \"tv\", \"tx\", \"ue\", \"ui\", \"uj\", \"uk\",\n",
        "    \"um\", \"un\", \"uo\", \"ur\", \"ut\", \"va\", \"wa\", \"vd\", \"wi\", \"vj\", \"vo\", \"wo\",\"vq\", \"vt\", \"vu\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\",\n",
        "    \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y2\", \"yj\", \"yl\", \"yr\", \"ys\", \"yt\", \"zi\", \"zz\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWMnKOMUyY4j",
        "colab_type": "text"
      },
      "source": [
        "# ***Text data cleaning framework***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sphwz-wuMKa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb-gYDwpMKfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_numbers(x):\n",
        "    x = re.sub('[0-9]{5,}', '#####', x)\n",
        "    x = re.sub('[0-9]{4}', '####', x)\n",
        "    x = re.sub('[0-9]{3}', '###', x)\n",
        "    x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZslfHGum0jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(x):\n",
        "    x = str(x).replace(\"\\n\",\"\")\n",
        "    \n",
        "    stops  = set(list(STOPWORDS)+add_stopwords)\n",
        "    text = [w for w in word_tokenize(x) if w not in stops]    \n",
        "    text = \" \".join(text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h76fZR5BMKk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoq0_1UKMKqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_typical_misspell(text):\n",
        "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "\n",
        "    return mispellings_re.sub(replace, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFrMZVoqMKop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unslang(text):\n",
        "    \"\"\"Converts text like \"OMG\" into \"Oh my God\"\n",
        "    \"\"\"\n",
        "    text = [slang_abbrev_dict[w.upper()] if w.upper() in slang_abbrev_dict.keys() else w for w in word_tokenize(text)]    \n",
        "    return \" \".join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0PpxyzqMKih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIeBLHIFMKd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMdSkuBPlDEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    return BeautifulSoup(text, \"lxml\").text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMYoFAyClDOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(df, col):\n",
        "        df[col] = df[col].apply(lambda x: clean_numbers(x))\n",
        "        df[col] = df[col].apply(lambda x: remove_urls(x))\n",
        "        df[col] = df[col].apply(lambda x: remove_html(x))\n",
        "        df[col] = df[col].apply(lambda text: remove_punctuation(text))\n",
        "        df[col] = df[col].apply(lambda x: clean_text(x.lower()))\n",
        "        df[col] = df[col].apply(lambda x: replace_typical_misspell(x))\n",
        "        df[col] = df[col].apply(lambda x: unslang(x))\n",
        "        df[col] = df[col].apply(lambda x: remove_emoji(x))\n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1m9iEi4lDWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = clean_data(train, 'text')\n",
        "test = clean_data(test, 'text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGzECWwxzp0u",
        "colab_type": "text"
      },
      "source": [
        "# ***Creating k-Folds (k=5) for training data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHuA4VhTxyzW",
        "colab_type": "code",
        "outputId": "a3df1a6e-e4ca-43f1-b903-2390e693a2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train[\"kfold\"] = -1\n",
        "\n",
        "    train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n",
        "\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X=train, y=train.target.values)):\n",
        "        print(len(train_idx), len(val_idx))\n",
        "        train.loc[val_idx, 'kfold'] = fold\n",
        "    \n",
        "\n",
        "    train.to_csv(\"train_folds.csv\", index=False)\n",
        "del train\n",
        "TRAINING_DATA = pd.read_csv('train_folds.csv')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6089 1524\n",
            "6090 1523\n",
            "6091 1522\n",
            "6091 1522\n",
            "6091 1522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vDoiDScDzda",
        "colab_type": "text"
      },
      "source": [
        "# ***Missing Value Imputation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTuEiDQDxrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing value filler \n",
        "TRAINING_DATA.keyword = TRAINING_DATA.keyword.fillna('No_Location')\n",
        "TRAINING_DATA.location = TRAINING_DATA.location.fillna('No_Location')\n",
        "test.keyword = test.keyword.fillna('No_Key')\n",
        "test.location = test.location.fillna('No_Location')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgbfm7jkEN2p",
        "colab_type": "text"
      },
      "source": [
        "# ***n-gram insights***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0tnaMgMFtsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n-gram generator\n",
        "def generate_ngrams(text, n_gram=1):\n",
        "  try:\n",
        "    token = [token for token in text.split(' ') if token != '' if token not in STOPWORDS]\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [' '.join(ngram) for ngram in ngrams]\n",
        "  except:\n",
        "    print(text)\n",
        "\n",
        "def n_gram_distribution_generator(n_gram=1):\n",
        "  disaster_ngrams = defaultdict(int)\n",
        "  nondisaster_ngrams = defaultdict(int)\n",
        "\n",
        "  for tweet in TRAINING_DATA.text[TRAINING_DATA.target==1]:\n",
        "      for word in generate_ngrams(tweet,n_gram=n_gram):\n",
        "          disaster_ngrams[word] += 1\n",
        "\n",
        "  for tweet in TRAINING_DATA.text[TRAINING_DATA.target==0]:\n",
        "      for word in generate_ngrams(tweet,n_gram=n_gram):\n",
        "          nondisaster_ngrams[word] += 1\n",
        "  df_disaster_ngrams= pd.DataFrame(disaster_ngrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)\n",
        "  df_non_disaster_ngrams = pd.DataFrame(nondisaster_ngrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)\n",
        "  return df_disaster_ngrams, df_non_disaster_ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtWC6XtYzdZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_DATA=TRAINING_DATA[-TRAINING_DATA.text.isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1RgtzAeaw79",
        "colab_type": "text"
      },
      "source": [
        "UNIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R0ZmJG2YjGm",
        "colab_type": "code",
        "outputId": "9f9e1041-6af8-4e04-faaa-d6b8381ef351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df_disaster_ngrams, df_non_disaster_ngrams = n_gram_distribution_generator(n_gram=1)\n",
        "print(f'frequency count of unigram for disaster tweets \\n {df_disaster_ngrams.head()}');\n",
        "print( f'frequency count of unigram for non-disaster tweets \\n {df_non_disaster_ngrams.head()}')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency count of unigram for disaster tweets \n",
            "            word  count\n",
            "58         news    136\n",
            "254    disaster    117\n",
            "81   california    111\n",
            "397     suicide    110\n",
            "31       police    106\n",
            "frequency count of unigram for non-disaster tweets \n",
            "        word  count\n",
            "21     dont    139\n",
            "16     body    112\n",
            "230   video     96\n",
            "163  people     92\n",
            "170       2     92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA5DbShzeCam",
        "colab_type": "text"
      },
      "source": [
        "BIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4zNCYcMbAnD",
        "colab_type": "code",
        "outputId": "3bf52c22-1e9a-4b0a-d70f-b4b713732991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df_disaster_ngrams, df_non_disaster_ngrams = n_gram_distribution_generator(n_gram=2)\n",
        "print(f'frequency count of bigram for disaster tweets \\n {df_disaster_ngrams.head()}');\n",
        "print( f'frequency count of bigram for non-disaster tweets \\n {df_non_disaster_ngrams.head()}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency count of bigram for disaster tweets \n",
            "                      word  count\n",
            "379        suicide bomber     59\n",
            "72    northern california     41\n",
            "1204            oil spill     38\n",
            "822     burning buildings     35\n",
            "73    california wildfire     34\n",
            "frequency count of bigram for non-disaster tweets \n",
            "               word  count\n",
            "818       Out Loud     60\n",
            "817   Laughing Out     60\n",
            "13      cross body     38\n",
            "381  youtube video     36\n",
            "14        body bag     26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VfestM5eRZG",
        "colab_type": "text"
      },
      "source": [
        "TRIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDsYXh0d-Vw",
        "colab_type": "code",
        "outputId": "28d3ca09-d6c8-4930-dc08-4db4e32ef552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "df_disaster_ngrams, df_non_disaster_ngrams = n_gram_distribution_generator(n_gram=3)\n",
        "print(f'frequency count of trigram for disaster tweets \\n {df_disaster_ngrams.head()}');\n",
        "print( f'frequency count of trigram for non-disaster tweets \\n {df_non_disaster_ngrams.head()}')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency count of trigram for disaster tweets \n",
            "                               word  count\n",
            "1708      suicide bomber detonated     30\n",
            "63    northern california wildfire     29\n",
            "60              latest homes razed     28\n",
            "61            homes razed northern     28\n",
            "2458         bomber detonated bomb     28\n",
            "frequency count of trigram for non-disaster tweets \n",
            "                              word  count\n",
            "699             Laughing Out Loud     60\n",
            "459   reddit quarantine offensive     18\n",
            "460  quarantine offensive content     18\n",
            "11                 cross body bag     18\n",
            "137                 pick fan army     17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAsptJAuEp5P",
        "colab_type": "text"
      },
      "source": [
        "# ***Feature Generation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSqjWr0CoUC",
        "colab_type": "code",
        "outputId": "9e90fcb5-07a4-4fb5-ebfc-d6b7840f7a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# feature_engineering on text column\n",
        "\n",
        "# char_count\n",
        "TRAINING_DATA['char_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x)))\n",
        "test['char_count'] = test['text'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# punctuation_count\n",
        "TRAINING_DATA['punctuation_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "test['punctuation_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "\n",
        "# hashtag_count\n",
        "TRAINING_DATA['hashtag_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "test['hashtag_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "\n",
        "# mention_count\n",
        "TRAINING_DATA['mention_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "test['mention_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "\n",
        "# unique_word_count\n",
        "TRAINING_DATA['unique_word_count'] = TRAINING_DATA['text'].apply(lambda x: len(set(str(x).split())))\n",
        "test['unique_word_count'] = test['text'].apply(lambda x: len(set(str(x).split())))\n",
        "\n",
        "# stop_word_count\n",
        "TRAINING_DATA['stop_word_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "test['stop_word_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "\n",
        "# url_count\n",
        "TRAINING_DATA['url_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "test['url_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "\n",
        "# mean_word_length\n",
        "TRAINING_DATA['mean_word_length'] = TRAINING_DATA['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test['mean_word_length'] = test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "# word_count\n",
        "TRAINING_DATA['word_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x).split()))\n",
        "test['word_count'] = test['text'].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QonmqDKTFto7",
        "colab_type": "code",
        "outputId": "6356eaf6-b866-4b48-8e5f-d8cd21c374c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "TRAINING_DATA.head(3)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>kfold</th>\n",
              "      <th>char_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>stop_word_count</th>\n",
              "      <th>url_count</th>\n",
              "      <th>mean_word_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4173</td>\n",
              "      <td>drown</td>\n",
              "      <td>Lynwood, CA</td>\n",
              "      <td>gon drown mustard lemon pepper</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8783</td>\n",
              "      <td>siren</td>\n",
              "      <td>Honolulu,Hawaii</td>\n",
              "      <td>serephina siren 3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5689</td>\n",
              "      <td>floods</td>\n",
              "      <td>Philippines</td>\n",
              "      <td>pagasa 7am yellow warning panay island guimara...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.571429</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id keyword          location  \\\n",
              "0  4173   drown       Lynwood, CA   \n",
              "1  8783   siren  Honolulu,Hawaii    \n",
              "2  5689  floods       Philippines   \n",
              "\n",
              "                                                text  target  kfold  \\\n",
              "0                     gon drown mustard lemon pepper       0      0   \n",
              "1                                  serephina siren 3       0      0   \n",
              "2  pagasa 7am yellow warning panay island guimara...       1      0   \n",
              "\n",
              "   char_count  punctuation_count  hashtag_count  mention_count  \\\n",
              "0          30                  0              0              0   \n",
              "1          17                  0              0              0   \n",
              "2         105                  0              0              0   \n",
              "\n",
              "   unique_word_count  stop_word_count  url_count  mean_word_length  word_count  \n",
              "0                  5                0          0          5.200000           5  \n",
              "1                  3                0          0          5.000000           3  \n",
              "2                 13                0          0          6.571429          14  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeKz7_ehCK2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsok8jJtlDUd",
        "colab_type": "code",
        "outputId": "f6a2802e-ea5a-4e55-8411-43fd63c63890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "TRAINING_DATA.text.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       gon drown mustard lemon pepper\n",
              "1                                    serephina siren 3\n",
              "2    pagasa 7am yellow warning panay island guimara...\n",
              "3    criminals hijack lorries buses arrested enugu ...\n",
              "4              critters climate plague deaths colorado\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sWKd-_3FWxb",
        "colab_type": "text"
      },
      "source": [
        "## ***text embedding using BERT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5DgIjS8lDJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunks(l, n):\n",
        "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i + n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUKD5RdnlDIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_vectors(string_list, batch_size=64):\n",
        "    # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    \n",
        "    # For DistilBERT:\n",
        "    model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "    \n",
        "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "    model = model_class.from_pretrained(pretrained_weights)\n",
        "    \n",
        "    model.to(DEVICE)\n",
        "\n",
        "    fin_features = []\n",
        "    for data in tqdm_notebook(chunks(string_list, batch_size)):\n",
        "        tokenized = []\n",
        "        for x in data:\n",
        "            x = \" \".join(x.strip().split()[:200])\n",
        "            tok = tokenizer.encode(x, add_special_tokens=True)\n",
        "            tokenized.append(tok[:512])\n",
        "\n",
        "        max_len = 512\n",
        "        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n",
        "        attention_mask = np.where(padded != 0, 1, 0)\n",
        "        input_ids = torch.tensor(padded).to(DEVICE)\n",
        "        attention_mask = torch.tensor(attention_mask).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "        \n",
        "        features = last_hidden_states[0][:, 0, :].cpu().numpy()\n",
        "        fin_features.append(features)\n",
        "\n",
        "    fin_features = np.vstack(fin_features)\n",
        "    return fin_features,tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W1yqDXmF5Df",
        "colab_type": "code",
        "outputId": "ff6fc2a3-902b-4266-ed38-4da0c10a68e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "fa93fae2e1d745e497da85491e79b4fc",
            "72385b43c8db406db1bb378fb2f6ada3",
            "d27fcb085a8044faa4b3044b025c3e34",
            "de569291be0b4e0ba35494cc05b80c24",
            "b891a50eb7664b2788a5f9a2b94d0c71",
            "499a75c2e8754b6895fa07f3498ed03c",
            "5ba46900de9740d78cec8ad13bd4bfe5",
            "fbef143908964ac192c569265babaac3",
            "cc83cc8e8a2c45369e5b28ae4f382ffd",
            "2c79fdb6b7fc40fbb8da1003c2a6e2ae",
            "7d8308ff28eb4cc08d3d998b9a1764f8",
            "7098dad9609f476c947a34aebfc36c95",
            "81aeb10b381d4f22abadd21344385b4a",
            "85c9f8c2d72d425dbbc7b04ac9ea0806",
            "503ca5cd969b41d9aee2efb78f148661",
            "729ae60ef6df488e9676e3760984ff77"
          ]
        }
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "train_dense,traintokenizer = fetch_vectors(TRAINING_DATA.text.values)\n",
        "test_dense,testtokenizer = fetch_vectors(test.text.values)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa93fae2e1d745e497da85491e79b4fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc83cc8e8a2c45369e5b28ae4f382ffd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oXr-47nsvLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert(len(train_dense)==TRAINING_DATA.shape[0])\n",
        "assert(len(test_dense)==test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ouUHQSF5Id",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2e1394d8-8eb2-4afc-f760-9ca042542d06"
      },
      "source": [
        "print(train_dense[:3]); print(test_dense[:3])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.26678988  0.07835416 -0.04069579 ... -0.13735893  0.18777059\n",
            "   0.3241973 ]\n",
            " [-0.2644404  -0.10522754 -0.13312659 ... -0.08269488  0.29187024\n",
            "   0.32950544]\n",
            " [-0.4256857  -0.01215183 -0.05950172 ... -0.09845211  0.34118354\n",
            "   0.01000265]]\n",
            "[[-0.25721332 -0.15935762 -0.13349877 ... -0.33479208  0.27146503\n",
            "   0.08463379]\n",
            " [-0.02239156 -0.19096556  0.01433134 ... -0.12936781  0.19693802\n",
            "   0.09040565]\n",
            " [-0.28844002  0.01489966 -0.1840436  ... -0.00638565  0.11386836\n",
            "   0.319541  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDHkAoHQF5OV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f951477-da4f-421e-a275-08129e91a14d"
      },
      "source": [
        "print(traintokenizer); print(testtokenizer)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<transformers.tokenization_distilbert.DistilBertTokenizer object at 0x7f1c344ca4e0>\n",
            "<transformers.tokenization_distilbert.DistilBertTokenizer object at 0x7f1c391ed6d8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LaDq7mmF5Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "1ad047ba-bd30-4a54-d30b-483e8cd7cf54"
      },
      "source": [
        "TRAINING_DATA.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>kfold</th>\n",
              "      <th>char_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>stop_word_count</th>\n",
              "      <th>url_count</th>\n",
              "      <th>mean_word_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4173</td>\n",
              "      <td>drown</td>\n",
              "      <td>Lynwood, CA</td>\n",
              "      <td>gon drown mustard lemon pepper</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8783</td>\n",
              "      <td>siren</td>\n",
              "      <td>Honolulu,Hawaii</td>\n",
              "      <td>serephina siren 3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5689</td>\n",
              "      <td>floods</td>\n",
              "      <td>Philippines</td>\n",
              "      <td>pagasa 7am yellow warning panay island guimara...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.571429</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6150</td>\n",
              "      <td>hijack</td>\n",
              "      <td>Nigeria</td>\n",
              "      <td>criminals hijack lorries buses arrested enugu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.428571</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3095</td>\n",
              "      <td>deaths</td>\n",
              "      <td>Washington, D.C.</td>\n",
              "      <td>critters climate plague deaths colorado</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id keyword          location  \\\n",
              "0  4173   drown       Lynwood, CA   \n",
              "1  8783   siren  Honolulu,Hawaii    \n",
              "2  5689  floods       Philippines   \n",
              "3  6150  hijack          Nigeria    \n",
              "4  3095  deaths  Washington, D.C.   \n",
              "\n",
              "                                                text  target  kfold  \\\n",
              "0                     gon drown mustard lemon pepper       0      0   \n",
              "1                                  serephina siren 3       0      0   \n",
              "2  pagasa 7am yellow warning panay island guimara...       1      0   \n",
              "3  criminals hijack lorries buses arrested enugu ...       1      0   \n",
              "4            critters climate plague deaths colorado       1      0   \n",
              "\n",
              "   char_count  punctuation_count  hashtag_count  mention_count  \\\n",
              "0          30                  0              0              0   \n",
              "1          17                  0              0              0   \n",
              "2         105                  0              0              0   \n",
              "3          51                  0              0              0   \n",
              "4          39                  0              0              0   \n",
              "\n",
              "   unique_word_count  stop_word_count  url_count  mean_word_length  word_count  \n",
              "0                  5                0          0          5.200000           5  \n",
              "1                  3                0          0          5.000000           3  \n",
              "2                 13                0          0          6.571429          14  \n",
              "3                  7                0          0          6.428571           7  \n",
              "4                  5                0          0          7.000000           5  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qemoNrxlF5G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54133ec4-1a69-4c5a-df84-910202c70114"
      },
      "source": [
        "train_dense_temp = pd.DataFrame(train_dense)\n",
        "train_dense_temp.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7608, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcvaZ9n9uq-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "83a56265-6cbb-4e1d-cdfe-b3d81de46f71"
      },
      "source": [
        "print(TRAINING_DATA.shape)\n",
        "print(train_dense_temp.shape)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7608, 15)\n",
            "(7608, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-VP9yknty89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f7edf3a-4fc4-4dca-d112-1b7a8ca20fb6"
      },
      "source": [
        "train_birt = pd.concat([TRAINING_DATA.reset_index(drop=True),train_dense_temp.reset_index(drop=True)],axis=1)\n",
        "train_birt.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7608, 783)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpMF6wdztmAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c015ddb-583f-4646-a6d8-4e3f6461bbf1"
      },
      "source": [
        "test_dense_temp = pd.DataFrame(test_dense)\n",
        "test_dense_temp.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lT_RCAkvWS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80a660dc-e34d-4327-fd7a-2382626323ec"
      },
      "source": [
        "test_birt = pd.concat([test.reset_index(drop=True),test_dense_temp.reset_index(drop=True)],axis=1)\n",
        "test_birt.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3263, 781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNk2PCMyvulq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cc8924e-9dad-449c-ce6f-05f90aa64aa6"
      },
      "source": [
        "set(TRAINING_DATA.columns)-set(test.columns)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kfold', 'target'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9USFMx8F3tm",
        "colab_type": "text"
      },
      "source": [
        "# ***Feature Engineering***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNyTJk7bwI04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3c2aa22e-65aa-4105-f71f-80f48b1056ad"
      },
      "source": [
        "train_birt.info()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7608 entries, 0 to 7607\n",
            "Columns: 783 entries, id to 767\n",
            "dtypes: float32(768), float64(1), int64(11), object(3)\n",
            "memory usage: 23.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVZeRr6owI4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "198cbcd8-b94b-49c9-b893-728652263a8e"
      },
      "source": [
        "test_birt.info()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Columns: 781 entries, id to 767\n",
            "dtypes: float32(768), float64(1), int64(9), object(3)\n",
            "memory usage: 9.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS53KZuSKM23",
        "colab_type": "text"
      },
      "source": [
        "## ***For Tree Models***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCXhPs3BJ4PB",
        "colab_type": "text"
      },
      "source": [
        "### ***Numerical Features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jztc1fnZKjwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK35AxwjKYvh",
        "colab_type": "text"
      },
      "source": [
        "### ***Categorical Features***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHFbc_xqwI8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsvEY9XfKnpH",
        "colab_type": "text"
      },
      "source": [
        "## ***For Linear & Neural Network Models***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-yD5Nt-Gwdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo5WHCxPGwg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDRpis8rGwk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGvLkf1eGwny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIVJbHPUGwqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2D1SAvpGwuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rU_6sZaGww0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaMx9x6qGwzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W86cn6tbJHuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODELS = {\n",
        "#     \"randomforest\": ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "#     \"extratrees\": ensemble.ExtraTreesClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "# }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCGRSvczd-gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FOLD_MAPPPING = {\n",
        "#     0: [1, 2, 3, 4],\n",
        "#     1: [0, 2, 3, 4],\n",
        "#     2: [0, 1, 3, 4],\n",
        "#     3: [0, 1, 2, 4],\n",
        "#     4: [0, 1, 2, 3]\n",
        "# }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C1NPyfN6FMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#   for MODEL in MODELS.keys():\n",
        "#     for FOLD in range(5):\n",
        "#       train_df = TRAINING_DATA[TRAINING_DATA.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\n",
        "#       valid_df = TRAINING_DATA[TRAINING_DATA.kfold==FOLD].reset_index(drop=True)\n",
        "\n",
        "#       ytrain = train_df.target.values\n",
        "#       yvalid = valid_df.target.values\n",
        "\n",
        "#       train_df = train_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "#       valid_df = valid_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "\n",
        "#       train_df.text = train_df.text.apply(lambda x : text_processor(x))\n",
        "#       valid_df.text = valid_df.text.apply(lambda x : text_processor(x))\n",
        "\n",
        "#       valid_df = valid_df[train_df.columns]\n",
        "\n",
        "#       # label_encoders = {}\n",
        "#       # for c in train_df.columns:\n",
        "#       #     lbl = preprocessing.LabelEncoder()\n",
        "#       #     lbl.fit(train_df[c].values.tolist() + valid_df[c].values.tolist() + df_test[c].values.tolist())\n",
        "#       #     train_df.loc[:, c] = lbl.transform(train_df[c].values.tolist())\n",
        "#       #     valid_df.loc[:, c] = lbl.transform(valid_df[c].values.tolist())\n",
        "#       #     label_encoders[c] = lbl\n",
        "      \n",
        "#       # data is ready to train\n",
        "#       clf = MODELS[MODEL]\n",
        "#       clf.fit(train_df, ytrain)\n",
        "#       preds = clf.predict_proba(valid_df)[:, 1]\n",
        "#       print(metrics.roc_auc_score(yvalid, preds))\n",
        "\n",
        "#       # joblib.dump(label_encoders, f\"models/{MODEL}_{FOLD}_label_encoder.pkl\")\n",
        "#       joblib.dump(clf, f\"models/{MODEL}_{FOLD}.pkl\")\n",
        "#       joblib.dump(train_df.columns, f\"models/{MODEL}_{FOLD}_columns.pkl\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}