{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_dsb_kids_game.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshavkmr48/Kaggle/blob/master/NLP_DISASTER_TWEET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OEZ_beau2Bn",
        "colab_type": "text"
      },
      "source": [
        "**Setting up kaggle API to download competition dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spsRa-6uyD5",
        "colab_type": "code",
        "outputId": "1e4ccc2c-9edd-4349-ed07-1e7a123f6a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# !pip install kaggle --upgrade\n",
        "! mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"keshavkmr48\",\"key\":\"014d22aa9430a95daaf028ec3e3463a2\"}\n",
        "with open('/content/.kaggle/kaggle.json','w') as file:\n",
        "  json.dump(token,file)\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# download competition data\n",
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 63.4MB/s]\n",
            "Downloading test.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 57.2MB/s]\n",
            "Downloading sample_submission.csv to {/content}/competitions/nlp-getting-started\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 23.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU618r3FwshF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from xgboost import plot_importance\n",
        "from sklearn import ensemble\n",
        "# from catboost import CatBoostRegressor\n",
        "from matplotlib import pyplot\n",
        "# import shap\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import gc, os\n",
        "import json\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from wordcloud import STOPWORDS\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import joblib\n",
        "pd.set_option('display.max_columns', 1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2HHLEk32NP",
        "colab_type": "code",
        "outputId": "3224aed6-5808-49b8-d760-b691df8b1189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# list data in the downloaded folder\n",
        "#os.listdir('{/content}/competitions/data-science-bowl-2019')\n",
        "os.chdir('{/content}/competitions/nlp-getting-started')\n",
        "os.listdir()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv', 'test.csv', 'sample_submission.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp1SSLMvw9yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    print('Reading train.csv file....')\n",
        "    train = pd.read_csv('train.csv')\n",
        "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
        "\n",
        "    print('Reading test.csv file....')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
        "\n",
        "\n",
        "    print('Reading sample_submission.csv file....')\n",
        "    sample_submission = pd.read_csv('sample_submission.csv')\n",
        "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
        "    return train, test, sample_submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYp1vR9y0fw",
        "colab_type": "code",
        "outputId": "1df57f78-8c56-4437-eac1-7988597a2f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train, test, sample_submission = read_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train.csv file....\n",
            "Training.csv file have 7613 rows and 5 columns\n",
            "Reading test.csv file....\n",
            "Test.csv file have 3263 rows and 4 columns\n",
            "Reading sample_submission.csv file....\n",
            "Sample_submission.csv file have 3263 rows and 2 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MvQIXL8wZ1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from multiprocessing import Pool\n",
        "\n",
        "# def json_loader(x):\n",
        "#   return json.loads(x)\n",
        "# pool = Pool(4)\n",
        "# result = pool.map_async(json_loader,train.event_data)\n",
        "# df = pd.DataFrame(list(result.get()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8wZoEmDy51E",
        "colab_type": "code",
        "outputId": "047051e2-ddc3-44b7-c4b2-76a27d8a923f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHuA4VhTxyzW",
        "colab_type": "code",
        "outputId": "c0d9f615-a893-4230-d346-ea0ff4179ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train[\"kfold\"] = -1\n",
        "\n",
        "    train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n",
        "\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X=train, y=train.target.values)):\n",
        "        print(len(train_idx), len(val_idx))\n",
        "        train.loc[val_idx, 'kfold'] = fold\n",
        "    \n",
        "\n",
        "    train.to_csv(\"train_folds.csv\", index=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6089 1524\n",
            "6090 1523\n",
            "6091 1522\n",
            "6091 1522\n",
            "6091 1522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2LRXNtq4664",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS = {\n",
        "    \"randomforest\": ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "    \"extratrees\": ensemble.ExtraTreesClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "}\n",
        "del train\n",
        "TRAINING_DATA = pd.read_csv('train_folds.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Genn8XSe6AHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLD_MAPPPING = {\n",
        "    0: [1, 2, 3, 4],\n",
        "    1: [0, 2, 3, 4],\n",
        "    2: [0, 1, 3, 4],\n",
        "    3: [0, 1, 2, 4],\n",
        "    4: [0, 1, 2, 3]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nxjlq8361BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vec embedding extraction\n",
        "def text_processor (text_value):\n",
        "  text = 'ram'\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSqjWr0CoUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature_engineering on text column\n",
        "\n",
        "# char_count\n",
        "TRAINING_DATA['char_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x)))\n",
        "test['char_count'] = test['text'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# punctuation_count\n",
        "TRAINING_DATA['punctuation_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "test['punctuation_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "\n",
        "# hashtag_count\n",
        "TRAINING_DATA['hashtag_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "test['hashtag_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "\n",
        "# mention_count\n",
        "TRAINING_DATA['mention_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "test['mention_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "\n",
        "# unique_word_count\n",
        "TRAINING_DATA['unique_word_count'] = TRAINING_DATA['text'].apply(lambda x: len(set(str(x).split())))\n",
        "test['unique_word_count'] = test['text'].apply(lambda x: len(set(str(x).split())))\n",
        "\n",
        "# stop_word_count\n",
        "TRAINING_DATA['stop_word_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "test['stop_word_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "\n",
        "# url_count\n",
        "TRAINING_DATA['url_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "test['url_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "\n",
        "# mean_word_length\n",
        "TRAINING_DATA['mean_word_length'] = TRAINING_DATA['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test['mean_word_length'] = test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "# word_count\n",
        "TRAINING_DATA['word_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x).split()))\n",
        "test['word_count'] = test['text'].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIE8msh9uXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing value filler \n",
        "TRAINING_DATA.keyword = TRAINING_DATA.keyword.fillna('No_Location')\n",
        "TRAINING_DATA.location = TRAINING_DATA.location.fillna('No_Location')\n",
        "test.keyword = test.keyword.fillna('No_Key')\n",
        "test.location = test.location.fillna('No_Location')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QonmqDKTFto7",
        "colab_type": "code",
        "outputId": "579d3d41-4c49-4a92-8d3a-d2f8483982e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "TRAINING_DATA.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>kfold</th>\n",
              "      <th>char_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>stop_word_count</th>\n",
              "      <th>url_count</th>\n",
              "      <th>mean_word_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6513</td>\n",
              "      <td>injuries</td>\n",
              "      <td>No_Location</td>\n",
              "      <td>@imSUSHIckoflove @alekalicante RIGHT?? Yep you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5.785714</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6371</td>\n",
              "      <td>hostages</td>\n",
              "      <td>Germany</td>\n",
              "      <td>@banditregina I also loved the episode 'Bang' ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>115</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>5.444444</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9698</td>\n",
              "      <td>tornado</td>\n",
              "      <td>No_Location</td>\n",
              "      <td>Brunette teen Giselle Locke teases at home htt...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>89</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>820</td>\n",
              "      <td>battle</td>\n",
              "      <td>CHICAGO (312)</td>\n",
              "      <td>Battle of the GOATS  https://t.co/ofECs6tcvC</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7.800000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8274</td>\n",
              "      <td>rioting</td>\n",
              "      <td>No_Location</td>\n",
              "      <td>RT : Why Sweden Isn't Venezuela: There have be...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>5.086957</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id   keyword       location  \\\n",
              "0  6513  injuries    No_Location   \n",
              "1  6371  hostages        Germany   \n",
              "2  9698   tornado    No_Location   \n",
              "3   820    battle  CHICAGO (312)   \n",
              "4  8274   rioting    No_Location   \n",
              "\n",
              "                                                text  target  kfold  \\\n",
              "0  @imSUSHIckoflove @alekalicante RIGHT?? Yep you...       0      0   \n",
              "1  @banditregina I also loved the episode 'Bang' ...       0      0   \n",
              "2  Brunette teen Giselle Locke teases at home htt...       0      0   \n",
              "3       Battle of the GOATS  https://t.co/ofECs6tcvC       0      0   \n",
              "4  RT : Why Sweden Isn't Venezuela: There have be...       1      0   \n",
              "\n",
              "   char_count  punctuation_count  hashtag_count  mention_count  \\\n",
              "0          94                  7              0              2   \n",
              "1         115                  7              0              1   \n",
              "2          89                  5              0              0   \n",
              "3          44                  5              0              0   \n",
              "4         139                  9              0              0   \n",
              "\n",
              "   unique_word_count  stop_word_count  url_count  mean_word_length  word_count  \n",
              "0                 13                6          0          5.785714          14  \n",
              "1                 16                7          0          5.444444          18  \n",
              "2                 12                2          1          6.500000          12  \n",
              "3                  5                2          1          7.800000           5  \n",
              "4                 23               12          1          5.086957          23  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0tnaMgMFtsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n-gram generator\n",
        "def generate_ngrams(text, n_gram=1):\n",
        "    token = [token for token in text.lower().split(' ') if token != '' if token not in STOPWORDS]\n",
        "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
        "    return [' '.join(ngram) for ngram in ngrams]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1RgtzAeaw79",
        "colab_type": "text"
      },
      "source": [
        "UNIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R0ZmJG2YjGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disaster_unigrams = defaultdict(int)\n",
        "nondisaster_unigrams = defaultdict(int)\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==1]:\n",
        "    for word in generate_ngrams(tweet,n_gram=1):\n",
        "        disaster_unigrams[word] += 1\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==0]:\n",
        "    for word in generate_ngrams(tweet):\n",
        "        nondisaster_unigrams[word] += 1\n",
        "df_disaster_unigrams= pd.DataFrame(disaster_unigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)\n",
        "df_non_disaster_unigrams = pd.DataFrame(nondisaster_unigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA5DbShzeCam",
        "colab_type": "text"
      },
      "source": [
        "BIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4zNCYcMbAnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disaster_bigrams = defaultdict(int)\n",
        "nondisaster_bigrams = defaultdict(int)\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==1]:\n",
        "    for word in generate_ngrams(tweet,n_gram=2):\n",
        "        disaster_bigrams[word] += 1\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==0]:\n",
        "    for word in generate_ngrams(tweet,n_gram=2):\n",
        "        nondisaster_bigrams[word] += 1\n",
        "df_disaster_bigrams= pd.DataFrame(disaster_bigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)\n",
        "df_non_disaster_bigrams = pd.DataFrame(nondisaster_bigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VfestM5eRZG",
        "colab_type": "text"
      },
      "source": [
        "TRIGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDsYXh0d-Vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disaster_trigrams = defaultdict(int)\n",
        "nondisaster_trigrams = defaultdict(int)\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==1]:\n",
        "    for word in generate_ngrams(tweet,n_gram=3):\n",
        "        disaster_trigrams[word] += 1\n",
        "\n",
        "for tweet in TRAINING_DATA.text[TRAINING_DATA.target==0]:\n",
        "    for word in generate_ngrams(tweet,n_gram=3):\n",
        "        nondisaster_trigrams[word] += 1\n",
        "df_disaster_trigrams= pd.DataFrame(disaster_trigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)\n",
        "df_non_disaster_trigrams = pd.DataFrame(nondisaster_trigrams.items(), columns=['word','count']).sort_values(by='count', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCGRSvczd-gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C1NPyfN6FMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  for MODEL in MODELS.keys():\n",
        "    for FOLD in range(5):\n",
        "      train_df = TRAINING_DATA[TRAINING_DATA.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\n",
        "      valid_df = TRAINING_DATA[TRAINING_DATA.kfold==FOLD].reset_index(drop=True)\n",
        "\n",
        "      ytrain = train_df.target.values\n",
        "      yvalid = valid_df.target.values\n",
        "\n",
        "      train_df = train_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "      valid_df = valid_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "\n",
        "      train_df.text = train_df.text.apply(lambda x : text_processor(x))\n",
        "      valid_df.text = valid_df.text.apply(lambda x : text_processor(x))\n",
        "\n",
        "      valid_df = valid_df[train_df.columns]\n",
        "\n",
        "      # label_encoders = {}\n",
        "      # for c in train_df.columns:\n",
        "      #     lbl = preprocessing.LabelEncoder()\n",
        "      #     lbl.fit(train_df[c].values.tolist() + valid_df[c].values.tolist() + df_test[c].values.tolist())\n",
        "      #     train_df.loc[:, c] = lbl.transform(train_df[c].values.tolist())\n",
        "      #     valid_df.loc[:, c] = lbl.transform(valid_df[c].values.tolist())\n",
        "      #     label_encoders[c] = lbl\n",
        "      \n",
        "      # data is ready to train\n",
        "      clf = MODELS[MODEL]\n",
        "      clf.fit(train_df, ytrain)\n",
        "      preds = clf.predict_proba(valid_df)[:, 1]\n",
        "      print(metrics.roc_auc_score(yvalid, preds))\n",
        "\n",
        "      # joblib.dump(label_encoders, f\"models/{MODEL}_{FOLD}_label_encoder.pkl\")\n",
        "      joblib.dump(clf, f\"models/{MODEL}_{FOLD}.pkl\")\n",
        "      joblib.dump(train_df.columns, f\"models/{MODEL}_{FOLD}_columns.pkl\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}