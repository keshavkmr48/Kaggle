{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_dsb_kids_game.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshavkmr48/Kaggle/blob/master/NLP_DISASTER_TWEET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OEZ_beau2Bn",
        "colab_type": "text"
      },
      "source": [
        "**Setting up kaggle API to download competition dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spsRa-6uyD5",
        "colab_type": "code",
        "outputId": "295513b4-8083-427c-82d0-7d13002a0139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# !pip install kaggle --upgrade\n",
        "# ! mkdir .kaggle\n",
        "# import json\n",
        "# token = {\"username\":\"keshavkmr48\",\"key\":\"014d22aa9430a95daaf028ec3e3463a2\"}\n",
        "# with open('/content/.kaggle/kaggle.json','w') as file:\n",
        "#   json.dump(token,file)\n",
        "#  !cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "#  !kaggle config set -n path -v{/content}\n",
        "#  !chmod 600 /root/.kaggle/kaggle.json\n",
        "# download competition data\n",
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU618r3FwshF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from xgboost import plot_importance\n",
        "from sklearn import ensemble\n",
        "# from catboost import CatBoostRegressor\n",
        "from matplotlib import pyplot\n",
        "# import shap\n",
        "from time import time\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import gc, os\n",
        "import json\n",
        "import string\n",
        "from wordcloud import STOPWORDS\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import joblib\n",
        "pd.set_option('display.max_columns', 1000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2HHLEk32NP",
        "colab_type": "code",
        "outputId": "c4f6e6f2-0470-4828-a520-df439b727aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# list data in the downloaded folder\n",
        "#os.listdir('{/content}/competitions/data-science-bowl-2019')\n",
        "os.chdir('{/content}/competitions/nlp-getting-started')\n",
        "os.listdir()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_folds.csv', 'train.csv', 'test.csv', 'sample_submission.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp1SSLMvw9yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    print('Reading train.csv file....')\n",
        "    train = pd.read_csv('train.csv')\n",
        "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
        "\n",
        "    print('Reading test.csv file....')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
        "\n",
        "\n",
        "    print('Reading sample_submission.csv file....')\n",
        "    sample_submission = pd.read_csv('sample_submission.csv')\n",
        "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
        "    return train, test, sample_submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQYp1vR9y0fw",
        "colab_type": "code",
        "outputId": "51af458e-9b0b-44c3-d0e7-99a38d1cd556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train, test, sample_submission = read_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading train.csv file....\n",
            "Training.csv file have 7613 rows and 5 columns\n",
            "Reading test.csv file....\n",
            "Test.csv file have 3263 rows and 4 columns\n",
            "Reading sample_submission.csv file....\n",
            "Sample_submission.csv file have 3263 rows and 2 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MvQIXL8wZ1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from multiprocessing import Pool\n",
        "\n",
        "# def json_loader(x):\n",
        "#   return json.loads(x)\n",
        "# pool = Pool(4)\n",
        "# result = pool.map_async(json_loader,train.event_data)\n",
        "# df = pd.DataFrame(list(result.get()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8wZoEmDy51E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "891e1a15-42a8-4e13-d593-58c443e79fe5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHuA4VhTxyzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "088e0c05-d250-4a67-b8b6-b40ee87f478f"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train[\"kfold\"] = -1\n",
        "\n",
        "    train = train.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=False, random_state=42)\n",
        "\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(X=train, y=train.target.values)):\n",
        "        print(len(train_idx), len(val_idx))\n",
        "        train.loc[val_idx, 'kfold'] = fold\n",
        "    \n",
        "\n",
        "    train.to_csv(\"train_folds.csv\", index=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6089 1524\n",
            "6090 1523\n",
            "6091 1522\n",
            "6091 1522\n",
            "6091 1522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2LRXNtq4664",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS = {\n",
        "    \"randomforest\": ensemble.RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "    \"extratrees\": ensemble.ExtraTreesClassifier(n_estimators=200, n_jobs=-1, verbose=2),\n",
        "}\n",
        "del train\n",
        "TRAINING_DATA = pd.read_csv('train_folds.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Genn8XSe6AHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOLD_MAPPPING = {\n",
        "    0: [1, 2, 3, 4],\n",
        "    1: [0, 2, 3, 4],\n",
        "    2: [0, 1, 3, 4],\n",
        "    3: [0, 1, 2, 4],\n",
        "    4: [0, 1, 2, 3]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nxjlq8361BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vec embedding extraction\n",
        "def text_processor (text_value):\n",
        "  text = 'ram'\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSqjWr0CoUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature_engineering on text column\n",
        "\n",
        "# char_count\n",
        "TRAINING_DATA['char_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x)))\n",
        "test['char_count'] = test['text'].apply(lambda x: len(str(x)))\n",
        "\n",
        "# punctuation_count\n",
        "TRAINING_DATA['punctuation_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "test['punctuation_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
        "\n",
        "# hashtag_count\n",
        "TRAINING_DATA['hashtag_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "test['hashtag_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
        "\n",
        "# mention_count\n",
        "TRAINING_DATA['mention_count'] = TRAINING_DATA['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "test['mention_count'] = test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
        "\n",
        "# unique_word_count\n",
        "TRAINING_DATA['unique_word_count'] = TRAINING_DATA['text'].apply(lambda x: len(set(str(x).split())))\n",
        "test['unique_word_count'] = test['text'].apply(lambda x: len(set(str(x).split())))\n",
        "\n",
        "# stop_word_count\n",
        "TRAINING_DATA['stop_word_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "test['stop_word_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
        "\n",
        "# url_count\n",
        "TRAINING_DATA['url_count'] = TRAINING_DATA['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "test['url_count'] = test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
        "\n",
        "# mean_word_length\n",
        "TRAINING_DATA['mean_word_length'] = TRAINING_DATA['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "test['mean_word_length'] = test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
        "# word_count\n",
        "TRAINING_DATA['word_count'] = TRAINING_DATA['text'].apply(lambda x: len(str(x).split()))\n",
        "test['word_count'] = test['text'].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIE8msh9uXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Missing value filler \n",
        "TRAINING_DATA.keyword = TRAINING_DATA.keyword.fillna('No_Location')\n",
        "TRAINING_DATA.location = TRAINING_DATA.location.fillna('No_Location')\n",
        "test.keyword = test.keyword.fillna('No_Key')\n",
        "test.location = test.location.fillna('No_Location')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QonmqDKTFto7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "e3550e83-6af0-495a-cc64-22b2dc21e1a4"
      },
      "source": [
        "TRAINING_DATA.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>kfold</th>\n",
              "      <th>char_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>unique_word_count</th>\n",
              "      <th>stop_word_count</th>\n",
              "      <th>url_count</th>\n",
              "      <th>mean_word_length</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9084</td>\n",
              "      <td>structural%20failure</td>\n",
              "      <td>VÌ_sterÌ´s, Sweden</td>\n",
              "      <td>@whvholst @leashless And this is a structural ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10052</td>\n",
              "      <td>twister</td>\n",
              "      <td>Long Island</td>\n",
              "      <td>@mrsbinker @EmilioRivera48 @davidlabrava Mine ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>5.272727</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8232</td>\n",
              "      <td>riot</td>\n",
              "      <td>No_Location</td>\n",
              "      <td>To All The Meat-Loving Feminists Of The World ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6.571429</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5642</td>\n",
              "      <td>flooding</td>\n",
              "      <td>?</td>\n",
              "      <td>@themaine is it too soon to start flooding you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4.578947</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6619</td>\n",
              "      <td>inundated</td>\n",
              "      <td>Toronto, ON, Canada</td>\n",
              "      <td>inundated with Westeros Between Storm of Sword...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>4.370370</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id               keyword             location  \\\n",
              "0   9084  structural%20failure   VÌ_sterÌ´s, Sweden   \n",
              "1  10052               twister          Long Island   \n",
              "2   8232                  riot          No_Location   \n",
              "3   5642              flooding                   ?    \n",
              "4   6619             inundated  Toronto, ON, Canada   \n",
              "\n",
              "                                                text  target  kfold  \\\n",
              "0  @whvholst @leashless And this is a structural ...       0      0   \n",
              "1  @mrsbinker @EmilioRivera48 @davidlabrava Mine ...       0      0   \n",
              "2  To All The Meat-Loving Feminists Of The World ...       0      0   \n",
              "3  @themaine is it too soon to start flooding you...       0      0   \n",
              "4  inundated with Westeros Between Storm of Sword...       0      0   \n",
              "\n",
              "   char_count  punctuation_count  hashtag_count  mention_count  \\\n",
              "0         133                  3              0              2   \n",
              "1         137                  4              0              3   \n",
              "2         105                  6              0              0   \n",
              "3         105                  4              0              1   \n",
              "4         144                  4              0              0   \n",
              "\n",
              "   unique_word_count  stop_word_count  url_count  mean_word_length  word_count  \n",
              "0                 19                9          0          5.700000          20  \n",
              "1                 22               11          0          5.272727          22  \n",
              "2                 13                6          1          6.571429          14  \n",
              "3                 18                8          0          4.578947          19  \n",
              "4                 24               13          0          4.370370          27  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0tnaMgMFtsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbMyuW6UFtmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C1NPyfN6FMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  for MODEL in MODELS.keys():\n",
        "    for FOLD in range(5):\n",
        "      train_df = TRAINING_DATA[TRAINING_DATA.kfold.isin(FOLD_MAPPPING.get(FOLD))].reset_index(drop=True)\n",
        "      valid_df = TRAINING_DATA[TRAINING_DATA.kfold==FOLD].reset_index(drop=True)\n",
        "\n",
        "      ytrain = train_df.target.values\n",
        "      yvalid = valid_df.target.values\n",
        "\n",
        "      train_df = train_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "      valid_df = valid_df.drop([\"id\", \"target\", \"kfold\"], axis=1)\n",
        "\n",
        "      train_df.text = train_df.text.apply(lambda x : text_processor(x))\n",
        "      valid_df.text = valid_df.text.apply(lambda x : text_processor(x))\n",
        "\n",
        "      valid_df = valid_df[train_df.columns]\n",
        "\n",
        "      # label_encoders = {}\n",
        "      # for c in train_df.columns:\n",
        "      #     lbl = preprocessing.LabelEncoder()\n",
        "      #     lbl.fit(train_df[c].values.tolist() + valid_df[c].values.tolist() + df_test[c].values.tolist())\n",
        "      #     train_df.loc[:, c] = lbl.transform(train_df[c].values.tolist())\n",
        "      #     valid_df.loc[:, c] = lbl.transform(valid_df[c].values.tolist())\n",
        "      #     label_encoders[c] = lbl\n",
        "      \n",
        "      # data is ready to train\n",
        "      clf = MODELS[MODEL]\n",
        "      clf.fit(train_df, ytrain)\n",
        "      preds = clf.predict_proba(valid_df)[:, 1]\n",
        "      print(metrics.roc_auc_score(yvalid, preds))\n",
        "\n",
        "      # joblib.dump(label_encoders, f\"models/{MODEL}_{FOLD}_label_encoder.pkl\")\n",
        "      joblib.dump(clf, f\"models/{MODEL}_{FOLD}.pkl\")\n",
        "      joblib.dump(train_df.columns, f\"models/{MODEL}_{FOLD}_columns.pkl\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}